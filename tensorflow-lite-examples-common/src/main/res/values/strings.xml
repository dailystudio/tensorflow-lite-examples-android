<resources>

    <string name="default_app_name">TensorFlow Lite Examples</string>
    <string name="default_example_desc">TensorFlow Lite is TensorFlo\'s lightweight solution for mobile and embedded devices. It enables low-latency inference of on-device machine learning models with a small binary size and fast performance supporting hardware acceleration.</string>

    <string name="action_about">About</string>
    <string name="action_settings">Settings</string>

    <string name="label_info_image_size">Image size</string>
    <string name="label_info_image_rotation">Image rotation</string>
    <string name="label_info_screen_rotation">Screen rotation</string>
    <string name="label_info_inference_image_size">Inference size</string>
    <string name="label_info_analysis_time">Analysis time</string>
    <string name="label_info_inference_time">Inference time</string>
    <string name="label_info_flatten_time">Flatten time</string>
    <string name="label_info_pre_process_time">Pre-process time</string>

    <string name="label_performance">Performance</string>
    <string name="label_settings">Settings</string>

    <string name="label_send">SEND</string>

    <string name="label_gpu">GPU</string>
    <string name="label_cpu">CPU</string>
    <string name="label_nnapi">Neural Network API</string>

    <string name="setting_device">Inference Device</string>
    <string name="setting_threads">Number of threads</string>

</resources>
